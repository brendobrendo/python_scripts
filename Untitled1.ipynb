{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e388ac9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76042b6aba6547cf9f36779d4f9d98cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500078458af04513b0d1737c01286fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02ae42d3339433eae72d1e558419bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2a5778a935480a9b2bfc1c6719da1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79338730bd2741aa8a20e31ff1b95e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5eb9d934824611bf8f1feef3c10fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A kernel is now ready.\n"
     ]
    }
   ],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion\n",
    "from semantic_kernel.connectors.ai.hugging_face import HuggingFaceTextCompletion\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "# else:\n",
    "#     api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "#     print(api_key, org_id)\n",
    "#     kernel.add_text_completion_service(\"openai\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "else:\n",
    "    kernel.add_text_completion_service(\"huggingface\", HuggingFaceTextCompletion(\"gpt2\", task=\"text-generation\"))\n",
    "    \n",
    "    \n",
    "print(\"A kernel is now ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae00da78",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "TextCompletionClientBase service with service_id 'None' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-8322f1d68587>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\"\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m summary_function = kernel.create_semantic_function(prompt_template = sk_prompt,\n\u001b[0m\u001b[1;32m      8\u001b[0m                                                   \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Summarizes the input to length of an old tweet.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                                   \u001b[0mmax_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/semantic_kernel/kernel.py\u001b[0m in \u001b[0;36mcreate_semantic_function\u001b[0;34m(self, prompt_template, function_name, skill_name, description, max_tokens, temperature, top_p, presence_penalty, frequency_penalty, number_of_responses, stop_sequences)\u001b[0m\n\u001b[1;32m    849\u001b[0m         \u001b[0mfunction_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSemanticFunctionConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 851\u001b[0;31m         return self.register_semantic_function(\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mskill_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/semantic_kernel/kernel.py\u001b[0m in \u001b[0;36mregister_semantic_function\u001b[0;34m(self, skill_name, function_name, function_config)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mvalidate_function_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         function = self._create_semantic_function(\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mskill_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/semantic_kernel/kernel.py\u001b[0m in \u001b[0;36m_create_semantic_function\u001b[0;34m(self, skill_name, function_name, function_config)\u001b[0m\n\u001b[1;32m    690\u001b[0m             \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_chat_service\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m             service = self.get_ai_service(\n\u001b[0m\u001b[1;32m    693\u001b[0m                 \u001b[0mTextCompletionClientBase\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                 \u001b[0mfunction_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_template_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_services\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/semantic_kernel/kernel.py\u001b[0m in \u001b[0;36mget_ai_service\u001b[0;34m(self, type, service_id)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mservice_id\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmatching_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    430\u001b[0m                 \u001b[0;34mf\"{type.__name__} service with service_id '{service_id}' not found\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: TextCompletionClientBase service with service_id 'None' not found"
     ]
    }
   ],
   "source": [
    "sk_prompt = \"\"\"\n",
    "{{$input}}\n",
    "\n",
    "Summarize the content above in less than 140 characters.\n",
    "\"\"\"\n",
    "\n",
    "summary_function = kernel.create_semantic_function(prompt_template = sk_prompt,\n",
    "                                                  description=\"Summarizes the input to length of an old tweet.\",\n",
    "                                                  max_tokens=200,\n",
    "                                                  temperature=0.1,\n",
    "                                                  top_p=0.5)\n",
    "\n",
    "print(\"A semantic function for summarization has been registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca842c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ec00e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
